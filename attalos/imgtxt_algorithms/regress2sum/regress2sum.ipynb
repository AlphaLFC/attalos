{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import Enum\n",
    "import gzip\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import dok_matrix, csr_matrix\n",
    "import tensorflow as tf\n",
    "\n",
    "# Attalos Imports\n",
    "import attalos.util.log.log as l\n",
    "from attalos.dataset.dataset import Dataset\n",
    "from attalos.evaluation.evaluation import Evaluation\n",
    "\n",
    "# Local models\n",
    "from mse import MSEModel\n",
    "from negsampling import NegSamplingModel\n",
    "from fast0tag import FastZeroTagModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup global objects\n",
    "logger = l.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from attalos.imgtxt_algorithms.regress2sum.multihot import MultihotModel\n",
    "from attalos.imgtxt_algorithms.regress2sum.naivesum import NaiveSumModel\n",
    "from attalos.imgtxt_algorithms.regress2sum.wdv import WDVModel\n",
    "from attalos.dataset.wordvectors.glove import GloveWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Temp object using duck typing to replace command line arguments\n",
    "args = lambda: None\n",
    "#args.image_feature_file_train = \"/local_data/teams/attalos/features/image/espgame_train_20160823_inception.hdf5\"\n",
    "#args.text_feature_file_train = \"/local_data/teams/attalos/features/text/espgame_train_20160823_text.json.gz\"\n",
    "#args.image_feature_file_test = \"/local_data/teams/attalos/features/image/espgame_test_20160823_inception.hdf5\"\n",
    "#args.text_feature_file_test = \"/local_data/teams/attalos/features/text/espgame_test_20160823_text.json.gz\"\n",
    "args.image_feature_file_train = \"/local_data/teams/attalos/features/image/iaprtc_train_20160816_inception.hdf5\"\n",
    "args.text_feature_file_train = \"/local_data/teams/attalos/features/text/iaprtc_train_20160816_text.json.gz\"\n",
    "args.image_feature_file_test = \"/local_data/teams/attalos/features/image/iaprtc_test_20160816_inception.hdf5\"\n",
    "args.text_feature_file_test = \"/local_data/teams/attalos/features/text/iaprtc_test_20160816_text.json.gz\"\n",
    "args.word_vector_file = \"/local_data/kylez/glove.6B.200d.txt\"\n",
    "args.word_vector_type = \"glove\"\n",
    "args.model_type = \"wdv\"\n",
    "args.cross_eval = False\n",
    "args.in_memory = True\n",
    "args.model_input_path = None\n",
    "args.model_output_path = None\n",
    "args.num_epochs = 400\n",
    "args.batch_size = 100\n",
    "args.learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WordVectorTypes(Enum):\n",
    "    w2v = 1\n",
    "    glove = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ModelTypes(Enum):\n",
    "    mse = 1\n",
    "    negsampling = 2\n",
    "    fast0tag = 3\n",
    "    multihot = MultihotModel\n",
    "    naivesum = NaiveSumModel\n",
    "    wdv = WDVModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_batch(sess, model, batch):\n",
    "    train_x, train_y = batch\n",
    "    training_loss = model.fit(sess, train_x, train_y)\n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(sess, model, train_dataset, batch_size):\n",
    "    training_losses = []\n",
    "    for cur_batch_num, batch in enumerate(model.to_batches(train_dataset, batch_size)):\n",
    "        training_loss = train_batch(sess, model, batch)\n",
    "        training_losses.append(training_loss)\n",
    "    avg_training_loss = sum(training_losses) / float(len(training_losses))\n",
    "    return avg_training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(sess, model, num_epochs, train_dataset, batch_size, epoch_verbosity_rate=10):\n",
    "    for cur_epoch in xrange(num_epochs):\n",
    "        verbose = cur_epoch % epoch_verbosity_rate == 0\n",
    "        avg_training_loss = train_epoch(sess, model, train_dataset, batch_size)\n",
    "        if verbose:\n",
    "            logger.info(\"Finished epoch %s. (Avg. training loss: %s)\" % (cur_epoch, avg_training_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_wv_model(word_vector_file, word_vector_type):\n",
    "    if args.word_vector_type == WordVectorTypes.glove.name:\n",
    "        from glove import Glove\n",
    "        glove_model = Glove.load_stanford(word_vector_file)\n",
    "        wv_model = GloveWrapper(glove_model)\n",
    "    else: #args.word_vector_type == WordVectorTypes.w2v.name:\n",
    "        import word2vec\n",
    "        w2v_model = word2vec.load(word_vector_file)\n",
    "        wv_model = W2VWrapper(w2v_model)\n",
    "    return wv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-09-09 19:37:07,239] [INFO] Parsing train and test datasets.\n",
      "[2016-09-09 19:37:07,557] [INFO] Reading word vectors from file.\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Parsing train and test datasets.\")\n",
    "train_dataset = Dataset(args.image_feature_file_train, args.text_feature_file_train, load_image_feats_in_mem=args.in_memory)\n",
    "test_dataset = Dataset(args.image_feature_file_test, args.text_feature_file_test)\n",
    "\n",
    "logger.info(\"Reading word vectors from file.\")\n",
    "wv_model = load_wv_model(args.word_vector_file, args.word_vector_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sess.close()\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-09-09 19:42:14,013] [INFO] Selecting model class: WDVModel\n",
      "[2016-09-09 19:42:18,153] [DEBUG] Constructing w1.\n",
      "[2016-09-09 19:42:25,909] [DEBUG] No specified vocab2. Setting w2 = w1.\n",
      "[2016-09-09 19:42:25,912] [DEBUG] Multiplying w1 and w2.\n",
      "[2016-09-09 19:42:25,916] [DEBUG] Applying preprocess_fn.\n",
      "[2016-09-09 19:42:26,021] [INFO] Input size: 2048\n",
      "[2016-09-09 19:42:26,022] [INFO] Output size: 288\n",
      "[2016-09-09 19:42:26,025] [INFO] Hidden layer size: 1168\n",
      "[2016-09-09 19:42:26,041] [INFO] Hidden layer size: 1168\n",
      "[2016-09-09 19:42:26,069] [INFO] Hidden layer size: 1168\n"
     ]
    }
   ],
   "source": [
    "model_cls = ModelTypes[args.model_type].value\n",
    "logger.info(\"Selecting model class: %s\" % model_cls.__name__)\n",
    "#datasets = [train_dataset] if args.cross_eval else [train_dataset, test_dataset]\n",
    "model = model_cls(wv_model, train_dataset=train_dataset, test_dataset=test_dataset, **vars(args))\n",
    "model.initialize_model(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-09-09 19:42:27,778] [INFO] Starting training phase.\n",
      "[2016-09-09 19:43:00,889] [INFO] Finished epoch 0. (Avg. training loss: 148.447199865)\n",
      "[2016-09-09 19:43:47,840] [INFO] Finished epoch 10. (Avg. training loss: 84.4973350005)\n",
      "[2016-09-09 19:44:12,841] [INFO] Finished epoch 20. (Avg. training loss: 77.1428703395)\n",
      "[2016-09-09 19:44:37,677] [INFO] Finished epoch 30. (Avg. training loss: 70.1581770724)\n",
      "[2016-09-09 19:45:02,589] [INFO] Finished epoch 40. (Avg. training loss: 63.6083343679)\n",
      "[2016-09-09 19:45:27,424] [INFO] Finished epoch 50. (Avg. training loss: 57.3654346466)\n",
      "[2016-09-09 19:45:52,148] [INFO] Finished epoch 60. (Avg. training loss: 51.9774155834)\n",
      "[2016-09-09 19:46:16,772] [INFO] Finished epoch 70. (Avg. training loss: 47.4211089394)\n",
      "[2016-09-09 19:46:41,418] [INFO] Finished epoch 80. (Avg. training loss: 43.7574630434)\n",
      "[2016-09-09 19:47:05,984] [INFO] Finished epoch 90. (Avg. training loss: 40.6061665362)\n",
      "[2016-09-09 19:47:30,622] [INFO] Finished epoch 100. (Avg. training loss: 38.0673392252)\n",
      "[2016-09-09 19:47:55,203] [INFO] Finished epoch 110. (Avg. training loss: 35.9420087771)\n",
      "[2016-09-09 19:48:19,998] [INFO] Finished epoch 120. (Avg. training loss: 34.2185067805)\n",
      "[2016-09-09 19:48:45,173] [INFO] Finished epoch 130. (Avg. training loss: 32.5745079517)\n",
      "[2016-09-09 19:49:10,628] [INFO] Finished epoch 140. (Avg. training loss: 31.3100394552)\n",
      "[2016-09-09 19:49:35,564] [INFO] Finished epoch 150. (Avg. training loss: 30.2041136893)\n",
      "[2016-09-09 19:50:00,309] [INFO] Finished epoch 160. (Avg. training loss: 29.1901725097)\n",
      "[2016-09-09 19:50:25,066] [INFO] Finished epoch 170. (Avg. training loss: 28.2223943689)\n",
      "[2016-09-09 19:50:49,680] [INFO] Finished epoch 180. (Avg. training loss: 27.4360638315)\n",
      "[2016-09-09 19:51:14,613] [INFO] Finished epoch 190. (Avg. training loss: 26.9947614887)\n",
      "[2016-09-09 19:51:39,810] [INFO] Finished epoch 200. (Avg. training loss: 26.4498278444)\n",
      "[2016-09-09 19:52:05,239] [INFO] Finished epoch 210. (Avg. training loss: 25.9491496411)\n",
      "[2016-09-09 19:52:30,263] [INFO] Finished epoch 220. (Avg. training loss: 25.496373079)\n",
      "[2016-09-09 19:52:55,188] [INFO] Finished epoch 230. (Avg. training loss: 24.8821093819)\n",
      "[2016-09-09 19:53:19,855] [INFO] Finished epoch 240. (Avg. training loss: 24.6430393349)\n",
      "[2016-09-09 19:53:44,620] [INFO] Finished epoch 250. (Avg. training loss: 24.1853265546)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b6925b5f7774>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Starting training phase.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#, train_dataset, wv_model, test_dataset=test_dataset, epoch_verbosity_rate=100)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-2a4e3dffde82>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(sess, model, num_epochs, train_dataset, batch_size, epoch_verbosity_rate)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcur_epoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcur_epoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mepoch_verbosity_rate\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mavg_training_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Finished epoch %s. (Avg. training loss: %s)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_training_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-99acce7af0d1>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(sess, model, train_dataset, batch_size)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtraining_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcur_batch_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mtraining_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mtraining_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mavg_training_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_losses\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-c53574bbbabb>\u001b[0m in \u001b[0;36mtrain_batch\u001b[1;34m(sess, model, batch)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtraining_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtraining_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/data/fs4/home/kylez/attalos/attalos/imgtxt_algorithms/regress2sum/wdv.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, sess, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"y_truth\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dropout_keep_prob\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdropout_keep_prob\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m                            })\n\u001b[0;32m    157\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 382\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    383\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 655\u001b[1;33m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 723\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    724\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    728\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    710\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m    711\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 712\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logger.info(\"Starting training phase.\")\n",
    "train(sess, model, args.num_epochs, train_dataset, args.batch_size) #, train_dataset, wv_model, test_dataset=test_dataset, epoch_verbosity_rate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-09-09 19:54:02,409] [INFO] Starting evaluation phase.\n",
      "/opt/conda/envs/python2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/envs/python2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[2016-09-09 19:54:02,965] [INFO] Evaluation (precision, recall, f1): [0.40860336819079413, 0.28596257579458823, 0.31335328330840467]\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Starting evaluation phase.\")\n",
    "test_x, test_y = model.to_ndarrs(test_dataset)\n",
    "predictions = model.predict(sess, test_x)\n",
    "evaluator = Evaluation(test_y, predictions, k=5)\n",
    "logger.info(\"Evaluation (precision, recall, f1): %s\" % evaluator.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = sess.run([model.model_info[\"predictions\"]], feed_dict={\n",
    "        model.model_info[\"input\"]: test_x\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_args_and_call_model(args):\n",
    "    #logger.info(\"Parsing train and test datasets.\")\n",
    "    #train_dataset = Dataset(args.image_feature_file_train, args.text_feature_file_train, load_image_feats_in_mem=args.in_memory)\n",
    "    #test_dataset = Dataset(args.image_feature_file_test, args.text_feature_file_test)\n",
    "    \n",
    "    #logger.info(\"Reading word vectors from file.\")\n",
    "    #wv_model = load_wv_model(args.word_vector_file, args.word_vector_type)\n",
    "    \n",
    "    #model_cls = ModelTypes[args.model_type].value\n",
    "    #logger.info(\"Selecting model class: %s\" % model_cls.__name__)\n",
    "    #datasets = [train_dataset] if args.cross_eval else [train_dataset, test_dataset]\n",
    "    #model = model_cls(wv_model, train_dataset=train_dataset, test_dataset=test_dataset, **vars(args))\n",
    "    \n",
    "    config = tf.ConfigProto(log_device_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        model.initialize_model(sess)\n",
    "        if args.model_input_path:\n",
    "            model.load(sess, args.model_input_path)\n",
    "        logger.info(\"Starting training phase.\")\n",
    "        train(sess, model, args.num_epochs, train_dataset, args.batch_size) #, train_dataset, wv_model, test_dataset=test_dataset, epoch_verbosity_rate=100)\n",
    "        if args.model_output_path:\n",
    "            model.save(sess, args.model_output_path)\n",
    "        \n",
    "        logger.info(\"Starting evaluation phase.\")\n",
    "        test_x, test_y = model.to_ndarrs(test_dataset)\n",
    "        predictions = model.predict(sess, test_x)\n",
    "        evaluator = Evaluation(test_y, predictions, k=5)\n",
    "        logger.info(\"Evaluation (precision, recall, f1): %s\" % evaluator.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-09-02 20:13:04,838] [INFO] Starting training phase.\n",
      "[2016-09-02 20:13:07,664] [INFO] Finished epoch 0. (Avg. training loss: 21181.0328813)\n",
      "[2016-09-02 20:13:33,584] [INFO] Finished epoch 10. (Avg. training loss: 12184.0612016)\n",
      "[2016-09-02 20:13:59,381] [INFO] Finished epoch 20. (Avg. training loss: 8148.95130782)\n",
      "[2016-09-02 20:14:25,179] [INFO] Finished epoch 30. (Avg. training loss: 6100.9630876)\n",
      "[2016-09-02 20:14:50,940] [INFO] Finished epoch 40. (Avg. training loss: 4878.23501587)\n",
      "[2016-09-02 20:15:16,740] [INFO] Finished epoch 50. (Avg. training loss: 4277.74039112)\n",
      "[2016-09-02 20:15:42,596] [INFO] Finished epoch 60. (Avg. training loss: 3689.44655817)\n",
      "[2016-09-02 20:16:08,485] [INFO] Finished epoch 70. (Avg. training loss: 3387.55152754)\n",
      "[2016-09-02 20:16:34,360] [INFO] Finished epoch 80. (Avg. training loss: 3101.4677665)\n",
      "[2016-09-02 20:17:00,272] [INFO] Finished epoch 90. (Avg. training loss: 2924.60223944)\n",
      "[2016-09-02 20:17:26,085] [INFO] Finished epoch 100. (Avg. training loss: 2800.04817755)\n",
      "[2016-09-02 20:17:51,831] [INFO] Finished epoch 110. (Avg. training loss: 2652.25124983)\n",
      "[2016-09-02 20:18:17,549] [INFO] Finished epoch 120. (Avg. training loss: 2460.68196245)\n",
      "[2016-09-02 20:18:43,901] [INFO] Finished epoch 130. (Avg. training loss: 2302.77708643)\n",
      "[2016-09-02 20:19:09,849] [INFO] Finished epoch 140. (Avg. training loss: 2240.77916648)\n",
      "[2016-09-02 20:19:35,645] [INFO] Finished epoch 150. (Avg. training loss: 2163.14223688)\n",
      "[2016-09-02 20:20:01,583] [INFO] Finished epoch 160. (Avg. training loss: 2078.40854506)\n",
      "[2016-09-02 20:20:27,654] [INFO] Finished epoch 170. (Avg. training loss: 2019.72849759)\n",
      "[2016-09-02 20:20:53,478] [INFO] Finished epoch 180. (Avg. training loss: 1927.40887521)\n",
      "[2016-09-02 20:21:19,280] [INFO] Finished epoch 190. (Avg. training loss: 1879.87232139)\n",
      "[2016-09-02 20:21:45,356] [INFO] Finished epoch 200. (Avg. training loss: 1835.27288263)\n",
      "[2016-09-02 20:22:11,171] [INFO] Finished epoch 210. (Avg. training loss: 1750.06011616)\n",
      "[2016-09-02 20:22:37,096] [INFO] Finished epoch 220. (Avg. training loss: 1722.41042813)\n",
      "[2016-09-02 20:23:02,872] [INFO] Finished epoch 230. (Avg. training loss: 1658.7402531)\n",
      "[2016-09-02 20:23:28,804] [INFO] Finished epoch 240. (Avg. training loss: 1592.20751745)\n",
      "[2016-09-02 20:23:54,799] [INFO] Finished epoch 250. (Avg. training loss: 1567.93846408)\n",
      "[2016-09-02 20:24:20,743] [INFO] Finished epoch 260. (Avg. training loss: 1531.20598602)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-6756079b24d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconvert_args_and_call_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-c5c103dd6c2d>\u001b[0m in \u001b[0;36mconvert_args_and_call_model\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_input_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Starting training phase.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#, train_dataset, wv_model, test_dataset=test_dataset, epoch_verbosity_rate=100)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_output_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_output_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-2a4e3dffde82>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(sess, model, num_epochs, train_dataset, batch_size, epoch_verbosity_rate)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcur_epoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcur_epoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mepoch_verbosity_rate\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mavg_training_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Finished epoch %s. (Avg. training loss: %s)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_training_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-99acce7af0d1>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(sess, model, train_dataset, batch_size)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtraining_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mcur_batch_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mtraining_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mtraining_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/data/fs4/home/kylez/attalos/attalos/imgtxt_algorithms/regress2sum/naivesum.pyc\u001b[0m in \u001b[0;36mto_batches\u001b[1;34m(self, dataset, batch_size)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mnum_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_images\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[0mimg_feats_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_feats_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_next_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mnew_img_feats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_feats_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/data/fs4/home/kylez/attalos/attalos/dataset/dataset.pyc\u001b[0m in \u001b[0;36mget_next_batch\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;31m# For each item to extract from the batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems_in_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mimg_feat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_feat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;31m# Add image features to output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/data/fs4/home/kylez/attalos/attalos/dataset/dataset.pyc\u001b[0m in \u001b[0;36mget_index\u001b[1;34m(self, item_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# Transform image index to image_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mitem_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;31m# Make sure our id's are strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/work/h5py/_objects.c:2696)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/work/h5py/_objects.c:2654)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/h5py/_hl/dataset.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[1;31m# HDF5 has a bug where if the memory shape has a different rank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[1;31m# than the dataset, the read is very slow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m             \u001b[1;31m# pad with ones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mmshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/work/h5py/_objects.c:2696)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/work/h5py/_objects.c:2654)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/h5py/_hl/dataset.pyc\u001b[0m in \u001b[0;36mshape\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[1;34m\"\"\"Numpy-style shape tuple giving dataset dimensions\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwith_phil\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "convert_args_and_call_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'WordVectorType' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-abbef5e5e7e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-abbef5e5e7e8>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m     parser.add_argument(\"--word_vector_type\",\n\u001b[0;32m     61\u001b[0m                        \u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m                        \u001b[0mchoices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mWordVectorType\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m                        help=\"Format of word_vector_file\")\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'WordVectorType' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Two layer linear regression')\n",
    "    parser.add_argument(\"image_feature_file_train\",\n",
    "                        type=str,\n",
    "                        help=\"Image Feature file for the training set\")\n",
    "    parser.add_argument(\"text_feature_file_train\",\n",
    "                        type=str,\n",
    "                        help=\"Text Feature file for the training set\")\n",
    "    parser.add_argument(\"image_feature_file_test\",\n",
    "                        type=str,\n",
    "                        help=\"Image Feature file for the test set\")\n",
    "    parser.add_argument(\"text_feature_file_test\",\n",
    "                        type=str,\n",
    "                        help=\"Text Feature file for the test set\")\n",
    "    parser.add_argument(\"word_vector_file\",\n",
    "                        type=str,\n",
    "                        help=\"Text file containing the word vectors\")\n",
    "\n",
    "    # Optional Args\n",
    "    parser.add_argument(\"--learning_rate\",\n",
    "                        type=float,\n",
    "                        default=.001,\n",
    "                        help=\"Learning Rate\")\n",
    "    parser.add_argument(\"--epochs\",\n",
    "                        type=int,\n",
    "                        default=200,\n",
    "                        help=\"Number of epochs to run for\")\n",
    "    parser.add_argument(\"--batch_size\",\n",
    "                        type=int,\n",
    "                        default=128,\n",
    "                        help=\"Batch size to use for training\")\n",
    "    parser.add_argument(\"--network\",\n",
    "                        type=str,\n",
    "                        default=\"200,200\",\n",
    "                        help=\"Define a neural network as comma separated layer sizes\")\n",
    "    parser.add_argument(\"--model_type\",\n",
    "                        type=str,\n",
    "                        default=\"mse\",\n",
    "                        choices=['mse', 'negsampling', 'fast0tag'],\n",
    "                        help=\"Loss function to use for training\")\n",
    "    parser.add_argument(\"--in_memory\",\n",
    "                        action='store_true',\n",
    "                        default=\"store_false\",\n",
    "                        help=\"Load training image features into memory for faster training\")\n",
    "    parser.add_argument(\"--model_input_path\",\n",
    "                        type=str,\n",
    "                        default=None,\n",
    "                        help=\"Model input path (to continue training)\")\n",
    "    parser.add_argument(\"--model_output_path\",\n",
    "                        type=str,\n",
    "                        default=None,\n",
    "                        help=\"Model output path (to save training)\")\n",
    "    \n",
    "    # new args\n",
    "    parser.add_argument(\"--cross_eval\",\n",
    "                        action=\"store_true\",\n",
    "                        default=False)\n",
    "    parser.add_argument(\"--word_vector_type\",\n",
    "                       type=str,\n",
    "                       choices=[t.name for t in WordVectorType],\n",
    "                       help=\"Format of word_vector_file\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    try:\n",
    "        # Sacred Imports\n",
    "        from sacred import Experiment\n",
    "        from sacred.observers import MongoObserver\n",
    "\n",
    "        from sacred.initialize import Scaffold\n",
    "\n",
    "        # Monkey patch to avoid having to declare all our variables\n",
    "        def noop(item):\n",
    "            pass\n",
    "        Scaffold._warn_about_suspicious_changes = noop\n",
    "\n",
    "        ex = Experiment('Regress2sum')\n",
    "        ex.observers.append(MongoObserver.create(url=os.environ['MONGO_DB_URI'],\n",
    "                                             db_name='attalos_experiment'))\n",
    "        ex.main(lambda: convert_args_and_call_model(args))\n",
    "        ex.run(config_updates=args.__dict__)\n",
    "    except ImportError:\n",
    "        # We don't have sacred, just run the script\n",
    "        convert_args_and_call_model(args)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_regressor(sess, model, val_image_feats, val_one_hot, wordmatrix, k=5, verbose=False):\n",
    "    \"\"\"\n",
    "    Takes a regressor and returns the precision/recall on the test data\n",
    "    Args:\n",
    "        sess: A tensorflow session\n",
    "        model_info: A dictionary containing tensorflow layers (specifically input and prediction)\n",
    "        val_image_feats: Image features to test performance on\n",
    "        val_text_tags: Text Tags to test performance on\n",
    "        w2v_model: a dictionary like object where the keys are words and the values are word vectors\n",
    "        k: Top number of items to retrieve to test precision/recall on\n",
    "        verbose: Verbose output or not\n",
    "\n",
    "    Returns:\n",
    "        evaluator: A attalos.evaluation.evaluation.Evaluation object\n",
    "    \"\"\"\n",
    "    val_pred = model.predict(sess, val_image_feats)\n",
    "    predictions = np.dot(val_pred, wordmatrix.T)\n",
    "\n",
    "    evaluator = Evaluation(val_one_hot, predictions, k)\n",
    "\n",
    "    return evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_wordmatrix(w2v_model, dataset=None):\n",
    "    \"\"\"\n",
    "    Take a w2v dictionary and return matrix/index lookup\n",
    "    Args:\n",
    "        w2vmodel: Dictionary where keys are words and values are word vectors\n",
    "        dataset: If specified limits tags in matrix to tags in dataset\n",
    "\n",
    "    Returns:\n",
    "        w2ind: Mapping of word to index\n",
    "        wordmatrix: Numpy matrix of word vectors\n",
    "    \"\"\"\n",
    "    dataset_tags = None\n",
    "    if dataset:\n",
    "        dataset_tags = set()\n",
    "        for tags in dataset.text_feats.values():\n",
    "            dataset_tags.update(tags)\n",
    "        num_tags_in_output = len(dataset_tags.intersection(w2v_model.keys()))\n",
    "    else:\n",
    "        num_tags_in_output = len(w2v_model)\n",
    "\n",
    "    # Create word vector matrix to allow for embedding lookup\n",
    "    w2ind = {}\n",
    "    wordmatrix = np.zeros((num_tags_in_output, len(w2v_model[w2v_model.keys()[0]])), dtype=np.float32)\n",
    "    i =0\n",
    "    for word in w2v_model:\n",
    "        if dataset_tags is None or word in dataset_tags:\n",
    "            w2ind[word] = i\n",
    "            wordmatrix[i, :] = w2v_model[word]\n",
    "            i += 1\n",
    "    return w2ind, wordmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataset_to_onehot(dataset, w2ind):\n",
    "    \"\"\"\n",
    "    Take a dataset and prepare it for convient evaluation\n",
    "    Args:\n",
    "        dataset: attalos.dataset.dataset object\n",
    "        w2ind: a dictionary like object mapping words to their index\n",
    "\n",
    "    Returns:\n",
    "        img_feats: A matrix of image feautres\n",
    "        one_hot: A sparse matrix of one hot tags\n",
    "\n",
    "    \"\"\"\n",
    "    image_feat, tags = dataset.get_index(0)\n",
    "\n",
    "    image_feats = np.zeros((dataset.num_images, image_feat.shape[0]))\n",
    "    one_hot = dok_matrix((dataset.num_images, len(w2ind)), dtype=np.int32)\n",
    "    # Extract features and place in numpy matrix\n",
    "    for i in dataset:\n",
    "        image_feat, tags = dataset[i]\n",
    "        image_feats[i, :] = image_feat\n",
    "        for tag in tags:\n",
    "            if tag in w2ind:\n",
    "                one_hot[i, w2ind[tag]] = 1\n",
    "\n",
    "    return image_feats, csr_matrix(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(train_dataset,\n",
    "                test_dataset,\n",
    "                w2v_model,\n",
    "                batch_size=128,\n",
    "                num_epochs=200,\n",
    "                learning_rate=1.001,\n",
    "                network_size=[200,200],\n",
    "                model_input_path = None,\n",
    "                model_output_path = None,\n",
    "                verbose=True,\n",
    "                model_type=ModelTypes.negsampling):\n",
    "    \"\"\"\n",
    "    Train a regression model to map image features into the word vector space\n",
    "    Args:\n",
    "        train_dataset: Training attalos.dataset.dataset object\n",
    "        test_dataset: Test attalos.dataset.dataset object\n",
    "        w2v_model: A dictionary like object where the keys are words and the values are word vectors\n",
    "        batch_size: Batch size to use for training\n",
    "        num_epochs: Number of epochs to train for\n",
    "        learning_rate: The learning rate for the network\n",
    "        network_size: A list defining the size of each layer of the neural network\n",
    "        model_input_path: Path to a file containing initial weights\n",
    "        model_output_path: Path to save final weights\n",
    "        verbose: Amounto fdebug information to output\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    # Get validation data\n",
    "    #  Extract features from first image\n",
    "    image_feats, tags = test_dataset.get_index(0)\n",
    "    # Get shape and initialize numpy matrix\n",
    "    image_feat_size = image_feats.shape[0]\n",
    "\n",
    "\n",
    "    # Turn w2v dictionary into a matrix\n",
    "    w2ind, word_matrix = create_wordmatrix(w2v_model)\n",
    "    val_w2ind, val_word_matrix = create_wordmatrix(w2v_model, test_dataset)\n",
    "\n",
    "    # Precompute onehot representation for evaluation\n",
    "    val_image_feats, val_one_hot = dataset_to_onehot(test_dataset, val_w2ind)\n",
    "\n",
    "\n",
    "    # Setup data structures for negative sampling\n",
    "    if model_type == ModelTypes.negsampling or model_type == ModelTypes.fast0tag:\n",
    "        word_counts = np.zeros(word_matrix.shape[0])\n",
    "        for item_id in train_dataset:\n",
    "            _, tags = train_dataset[item_id]\n",
    "            for tag in tags:\n",
    "                if tag in w2ind:\n",
    "                    word_counts[w2ind[tag]] += 1\n",
    "        labelpdf = word_counts / word_counts.sum()\n",
    "        vocabsize = word_matrix.shape[0]\n",
    "        def negsamp(ignored_inds, num2samp):\n",
    "            # Negative sampler that takes in indicies\n",
    "\n",
    "            # Create new probability vector excluding positive samples\n",
    "            nlabelpdf = np.copy(labelpdf)\n",
    "            nlabelpdf[ignored_inds] = 0\n",
    "            nlabelpdf /= nlabelpdf.sum()\n",
    "\n",
    "            return np.random.choice(vocabsize, size=num2samp, p=nlabelpdf)\n",
    "\n",
    "    # Time to start building our graph\n",
    "    with tf.Graph().as_default():\n",
    "        # Build regressor\n",
    "        if model_type == ModelTypes.mse:\n",
    "            logger.info('Building regressor with mean square error loss')\n",
    "            model = MSEModel(image_feat_size,\n",
    "                                         word_matrix,\n",
    "                                        learning_rate=learning_rate,\n",
    "                                        hidden_units=network_size,\n",
    "                                        use_batch_norm=True)\n",
    "        elif model_type == ModelTypes.negsampling:\n",
    "            logger.info('Building regressor with negative sampling loss')\n",
    "            model = NegSamplingModel(image_feat_size,\n",
    "                                        word_matrix,\n",
    "                                        learning_rate=learning_rate,\n",
    "                                        hidden_units=network_size,\n",
    "                                        use_batch_norm=True)\n",
    "        elif model_type == ModelTypes.fast0tag:\n",
    "            logger.info('Building model with fast zero tag loss')\n",
    "            model = FastZeroTagModel(image_feat_size,\n",
    "                                        word_matrix,\n",
    "                                        learning_rate=learning_rate,\n",
    "                                        hidden_units=network_size,\n",
    "                                        use_batch_norm=True)\n",
    "\n",
    "        # Allocate GPU memory as needed (vs. allocating all the memory)\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        with tf.Session(config=config) as sess:\n",
    "            # Initialize model\n",
    "            model.initialize_model(sess)\n",
    "\n",
    "            # Optionally restore saved model\n",
    "            if model_input_path:\n",
    "                model.load(sess, model_input_path)\n",
    "\n",
    "            NUM_POSTIVE_EXAMPLES = 5\n",
    "            NUM_NEGATIVE_EXAMPLES = 10\n",
    "            # Reuse space for each iteration\n",
    "            pos_word_ids = np.ones((batch_size, NUM_POSTIVE_EXAMPLES), dtype=np.int32)\n",
    "            neg_word_ids = np.ones((batch_size, NUM_NEGATIVE_EXAMPLES), dtype=np.int32)\n",
    "            performance = []\n",
    "            for epoch in range(num_epochs):\n",
    "                batch_time_total = 0\n",
    "                run_time_total = 0\n",
    "\n",
    "                loss = None\n",
    "                for batch in range(int(train_dataset.num_images/batch_size)):\n",
    "                    batch_time = time.time()\n",
    "                    # Get raw data\n",
    "                    image_feats, text_tags = train_dataset.get_next_batch(batch_size)\n",
    "\n",
    "                    # Generate positive examples\n",
    "                    pos_word_ids.fill(-1)\n",
    "                    for i, tags in enumerate(text_tags):\n",
    "                        j = 0\n",
    "                        for tag in tags:\n",
    "                            if tag in w2ind and j < NUM_POSTIVE_EXAMPLES:\n",
    "                                pos_word_ids[i, j] = w2ind[tag]\n",
    "                                j += 1\n",
    "\n",
    "                    if model_type == ModelTypes.negsampling or model_type == ModelTypes.fast0tag:\n",
    "                        neg_word_ids.fill(-1)\n",
    "                        for i in range(neg_word_ids.shape[0]):\n",
    "                            neg_word_ids[i] = negsamp(pos_word_ids, NUM_NEGATIVE_EXAMPLES)\n",
    "\n",
    "                    batch_time = time.time() - batch_time\n",
    "                    batch_time_total += batch_time\n",
    "\n",
    "                    run_time = time.time()\n",
    "                    if model_type == ModelTypes.mse:\n",
    "                        loss = model.fit(sess, image_feats, pos_word_ids)\n",
    "                    elif model_type == ModelTypes.negsampling or model_type == ModelTypes.fast0tag:\n",
    "                        loss = model.fit(sess, image_feats,pos_word_ids, neg_word_ids=neg_word_ids)\n",
    "                    run_time = time.time() - run_time\n",
    "                    run_time_total += run_time\n",
    "\n",
    "                if verbose:\n",
    "                    eval_time = time.time()\n",
    "                    evaluator = evaluate_regressor(sess, model, val_image_feats, val_one_hot, val_word_matrix, verbose=False)\n",
    "                    performance.append(evaluator.evaluate())\n",
    "                    eval_time = time.time() - eval_time\n",
    "                    # Evaluate accuracy\n",
    "                    #print('Epoch {}: Loss: {} Timing: {} {} {}'.format(epoch, loss, batch_time_total, run_time_total, eval_time))\n",
    "                    logger.debug('Epoch {}: Loss: {} Perf: {} {} {}'.format(epoch, loss, *performance[-1]))\n",
    "\n",
    "            if model_output_path:\n",
    "                model.save(sess, model_output_path)\n",
    "\n",
    "            return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016-09-02 20:28:54,605] [INFO] Starting training phase.\n",
      "[2016-09-02 20:28:57,225] [INFO] Finished epoch 0. (Avg. training loss: 21108.685902)\n",
      "[2016-09-02 20:29:23,264] [INFO] Finished epoch 10. (Avg. training loss: 12104.3950084)\n",
      "[2016-09-02 20:29:49,075] [INFO] Finished epoch 20. (Avg. training loss: 8269.83771584)\n",
      "[2016-09-02 20:30:15,403] [INFO] Finished epoch 30. (Avg. training loss: 6266.67783425)\n",
      "[2016-09-02 20:30:41,737] [INFO] Finished epoch 40. (Avg. training loss: 5189.87184837)\n",
      "[2016-09-02 20:31:07,973] [INFO] Finished epoch 50. (Avg. training loss: 4396.46431108)\n",
      "[2016-09-02 20:31:34,121] [INFO] Finished epoch 60. (Avg. training loss: 3863.6595348)\n",
      "[2016-09-02 20:32:00,056] [INFO] Finished epoch 70. (Avg. training loss: 3587.67546914)\n",
      "[2016-09-02 20:32:25,970] [INFO] Finished epoch 80. (Avg. training loss: 3379.37619296)\n",
      "[2016-09-02 20:32:52,125] [INFO] Finished epoch 90. (Avg. training loss: 3126.55012651)\n",
      "[2016-09-02 20:33:17,865] [INFO] Finished epoch 100. (Avg. training loss: 2957.23998885)\n",
      "[2016-09-02 20:33:43,841] [INFO] Finished epoch 110. (Avg. training loss: 2796.72104298)\n",
      "[2016-09-02 20:34:09,856] [INFO] Finished epoch 120. (Avg. training loss: 2606.55410073)\n",
      "[2016-09-02 20:34:35,776] [INFO] Finished epoch 130. (Avg. training loss: 2557.84210968)\n",
      "[2016-09-02 20:35:01,677] [INFO] Finished epoch 140. (Avg. training loss: 2437.01763084)\n",
      "[2016-09-02 20:35:27,572] [INFO] Finished epoch 150. (Avg. training loss: 2332.99427587)\n",
      "[2016-09-02 20:35:53,492] [INFO] Finished epoch 160. (Avg. training loss: 2282.81213587)\n",
      "[2016-09-02 20:36:19,444] [INFO] Finished epoch 170. (Avg. training loss: 2183.19040819)\n",
      "[2016-09-02 20:36:45,283] [INFO] Finished epoch 180. (Avg. training loss: 2105.26487801)\n",
      "[2016-09-02 20:37:11,196] [INFO] Finished epoch 190. (Avg. training loss: 2055.16294514)\n",
      "[2016-09-02 20:37:37,021] [INFO] Finished epoch 200. (Avg. training loss: 1946.56969729)\n",
      "[2016-09-02 20:38:02,942] [INFO] Finished epoch 210. (Avg. training loss: 1904.94288358)\n",
      "[2016-09-02 20:38:28,624] [INFO] Finished epoch 220. (Avg. training loss: 1876.2755016)\n",
      "[2016-09-02 20:38:54,413] [INFO] Finished epoch 230. (Avg. training loss: 1760.27381689)\n",
      "[2016-09-02 20:39:20,242] [INFO] Finished epoch 240. (Avg. training loss: 1746.02444597)\n",
      "[2016-09-02 20:39:46,173] [INFO] Finished epoch 250. (Avg. training loss: 1707.82103105)\n",
      "[2016-09-02 20:40:12,130] [INFO] Finished epoch 260. (Avg. training loss: 1684.19585557)\n",
      "[2016-09-02 20:40:37,957] [INFO] Finished epoch 270. (Avg. training loss: 1653.4075685)\n",
      "[2016-09-02 20:41:03,652] [INFO] Finished epoch 280. (Avg. training loss: 1612.74879039)\n",
      "[2016-09-02 20:41:29,855] [INFO] Finished epoch 290. (Avg. training loss: 1648.05460843)\n",
      "[2016-09-02 20:41:55,827] [INFO] Finished epoch 300. (Avg. training loss: 1574.80913405)\n",
      "[2016-09-02 20:42:21,778] [INFO] Finished epoch 310. (Avg. training loss: 1603.2134122)\n",
      "[2016-09-02 20:42:47,699] [INFO] Finished epoch 320. (Avg. training loss: 1554.92467221)\n",
      "[2016-09-02 20:43:13,587] [INFO] Finished epoch 330. (Avg. training loss: 1510.93893363)\n",
      "[2016-09-02 20:43:39,812] [INFO] Finished epoch 340. (Avg. training loss: 1467.54254913)\n",
      "[2016-09-02 20:44:05,688] [INFO] Finished epoch 350. (Avg. training loss: 1440.12515883)\n",
      "[2016-09-02 20:44:31,621] [INFO] Finished epoch 360. (Avg. training loss: 1422.47295414)\n",
      "[2016-09-02 20:44:57,927] [INFO] Finished epoch 370. (Avg. training loss: 1444.78291529)\n",
      "[2016-09-02 20:45:24,529] [INFO] Finished epoch 380. (Avg. training loss: 1392.09626389)\n",
      "[2016-09-02 20:45:50,543] [INFO] Finished epoch 390. (Avg. training loss: 1384.02797976)\n",
      "[2016-09-02 20:46:16,563] [INFO] Finished epoch 400. (Avg. training loss: 1345.65613417)\n",
      "[2016-09-02 20:46:42,446] [INFO] Finished epoch 410. (Avg. training loss: 1358.62544875)\n",
      "[2016-09-02 20:47:08,529] [INFO] Finished epoch 420. (Avg. training loss: 1372.39384114)\n",
      "[2016-09-02 20:47:34,725] [INFO] Finished epoch 430. (Avg. training loss: 1314.77864317)\n",
      "[2016-09-02 20:48:00,873] [INFO] Finished epoch 440. (Avg. training loss: 1336.18339539)\n",
      "[2016-09-02 20:48:27,202] [INFO] Finished epoch 450. (Avg. training loss: 1319.19177315)\n",
      "[2016-09-02 20:48:53,409] [INFO] Finished epoch 460. (Avg. training loss: 1311.66452096)\n",
      "[2016-09-02 20:49:19,906] [INFO] Finished epoch 470. (Avg. training loss: 1288.18096993)\n",
      "[2016-09-02 20:49:46,107] [INFO] Finished epoch 480. (Avg. training loss: 1300.70907697)\n",
      "[2016-09-02 20:50:12,178] [INFO] Finished epoch 490. (Avg. training loss: 1299.08323045)\n",
      "[2016-09-02 20:50:38,245] [INFO] Finished epoch 500. (Avg. training loss: 1262.9536653)\n",
      "[2016-09-02 20:51:04,312] [INFO] Finished epoch 510. (Avg. training loss: 1285.90589003)\n",
      "[2016-09-02 20:51:30,407] [INFO] Finished epoch 520. (Avg. training loss: 1294.46736214)\n",
      "[2016-09-02 20:51:56,662] [INFO] Finished epoch 530. (Avg. training loss: 1303.53440371)\n",
      "[2016-09-02 20:52:22,815] [INFO] Finished epoch 540. (Avg. training loss: 1249.16370045)\n",
      "[2016-09-02 20:52:48,962] [INFO] Finished epoch 550. (Avg. training loss: 1236.94174333)\n",
      "[2016-09-02 20:53:15,086] [INFO] Finished epoch 560. (Avg. training loss: 1224.01751952)\n",
      "[2016-09-02 20:53:41,849] [INFO] Finished epoch 570. (Avg. training loss: 1224.03992566)\n",
      "[2016-09-02 20:54:08,209] [INFO] Finished epoch 580. (Avg. training loss: 1230.53211316)\n",
      "[2016-09-02 20:54:34,086] [INFO] Finished epoch 590. (Avg. training loss: 1234.63750805)\n",
      "[2016-09-02 20:54:59,818] [INFO] Finished epoch 600. (Avg. training loss: 1221.07882378)\n",
      "[2016-09-02 20:55:26,642] [INFO] Finished epoch 610. (Avg. training loss: 1185.65967248)\n",
      "[2016-09-02 20:55:52,400] [INFO] Finished epoch 620. (Avg. training loss: 1194.03575446)\n",
      "[2016-09-02 20:56:18,263] [INFO] Finished epoch 630. (Avg. training loss: 1194.08644208)\n",
      "[2016-09-02 20:56:44,197] [INFO] Finished epoch 640. (Avg. training loss: 1183.59341639)\n",
      "[2016-09-02 20:57:10,383] [INFO] Finished epoch 650. (Avg. training loss: 1183.01943727)\n",
      "[2016-09-02 20:57:36,872] [INFO] Finished epoch 660. (Avg. training loss: 1158.40334736)\n",
      "[2016-09-02 20:58:02,976] [INFO] Finished epoch 670. (Avg. training loss: 1174.4918095)\n",
      "[2016-09-02 20:58:29,014] [INFO] Finished epoch 680. (Avg. training loss: 1199.12700064)\n",
      "[2016-09-02 20:58:54,746] [INFO] Finished epoch 690. (Avg. training loss: 1160.72963125)\n",
      "[2016-09-02 20:59:20,790] [INFO] Finished epoch 700. (Avg. training loss: 1165.32282188)\n",
      "[2016-09-02 20:59:46,938] [INFO] Finished epoch 710. (Avg. training loss: 1174.37212615)\n",
      "[2016-09-02 21:00:13,340] [INFO] Finished epoch 720. (Avg. training loss: 1169.23551282)\n",
      "[2016-09-02 21:00:39,339] [INFO] Finished epoch 730. (Avg. training loss: 1122.53124688)\n",
      "[2016-09-02 21:01:05,179] [INFO] Finished epoch 740. (Avg. training loss: 1157.93275036)\n",
      "[2016-09-02 21:01:31,381] [INFO] Finished epoch 750. (Avg. training loss: 1158.09665056)\n",
      "[2016-09-02 21:01:57,537] [INFO] Finished epoch 760. (Avg. training loss: 1139.63393333)\n"
     ]
    }
   ],
   "source": [
    "print \"\"\"[2016-09-02 20:28:54,605] [INFO] Starting training phase.\n",
    "[2016-09-02 20:28:57,225] [INFO] Finished epoch 0. (Avg. training loss: 21108.685902)\n",
    "[2016-09-02 20:29:23,264] [INFO] Finished epoch 10. (Avg. training loss: 12104.3950084)\n",
    "[2016-09-02 20:29:49,075] [INFO] Finished epoch 20. (Avg. training loss: 8269.83771584)\n",
    "[2016-09-02 20:30:15,403] [INFO] Finished epoch 30. (Avg. training loss: 6266.67783425)\n",
    "[2016-09-02 20:30:41,737] [INFO] Finished epoch 40. (Avg. training loss: 5189.87184837)\n",
    "[2016-09-02 20:31:07,973] [INFO] Finished epoch 50. (Avg. training loss: 4396.46431108)\n",
    "[2016-09-02 20:31:34,121] [INFO] Finished epoch 60. (Avg. training loss: 3863.6595348)\n",
    "[2016-09-02 20:32:00,056] [INFO] Finished epoch 70. (Avg. training loss: 3587.67546914)\n",
    "[2016-09-02 20:32:25,970] [INFO] Finished epoch 80. (Avg. training loss: 3379.37619296)\n",
    "[2016-09-02 20:32:52,125] [INFO] Finished epoch 90. (Avg. training loss: 3126.55012651)\n",
    "[2016-09-02 20:33:17,865] [INFO] Finished epoch 100. (Avg. training loss: 2957.23998885)\n",
    "[2016-09-02 20:33:43,841] [INFO] Finished epoch 110. (Avg. training loss: 2796.72104298)\n",
    "[2016-09-02 20:34:09,856] [INFO] Finished epoch 120. (Avg. training loss: 2606.55410073)\n",
    "[2016-09-02 20:34:35,776] [INFO] Finished epoch 130. (Avg. training loss: 2557.84210968)\n",
    "[2016-09-02 20:35:01,677] [INFO] Finished epoch 140. (Avg. training loss: 2437.01763084)\n",
    "[2016-09-02 20:35:27,572] [INFO] Finished epoch 150. (Avg. training loss: 2332.99427587)\n",
    "[2016-09-02 20:35:53,492] [INFO] Finished epoch 160. (Avg. training loss: 2282.81213587)\n",
    "[2016-09-02 20:36:19,444] [INFO] Finished epoch 170. (Avg. training loss: 2183.19040819)\n",
    "[2016-09-02 20:36:45,283] [INFO] Finished epoch 180. (Avg. training loss: 2105.26487801)\n",
    "[2016-09-02 20:37:11,196] [INFO] Finished epoch 190. (Avg. training loss: 2055.16294514)\n",
    "[2016-09-02 20:37:37,021] [INFO] Finished epoch 200. (Avg. training loss: 1946.56969729)\n",
    "[2016-09-02 20:38:02,942] [INFO] Finished epoch 210. (Avg. training loss: 1904.94288358)\n",
    "[2016-09-02 20:38:28,624] [INFO] Finished epoch 220. (Avg. training loss: 1876.2755016)\n",
    "[2016-09-02 20:38:54,413] [INFO] Finished epoch 230. (Avg. training loss: 1760.27381689)\n",
    "[2016-09-02 20:39:20,242] [INFO] Finished epoch 240. (Avg. training loss: 1746.02444597)\n",
    "[2016-09-02 20:39:46,173] [INFO] Finished epoch 250. (Avg. training loss: 1707.82103105)\n",
    "[2016-09-02 20:40:12,130] [INFO] Finished epoch 260. (Avg. training loss: 1684.19585557)\n",
    "[2016-09-02 20:40:37,957] [INFO] Finished epoch 270. (Avg. training loss: 1653.4075685)\n",
    "[2016-09-02 20:41:03,652] [INFO] Finished epoch 280. (Avg. training loss: 1612.74879039)\n",
    "[2016-09-02 20:41:29,855] [INFO] Finished epoch 290. (Avg. training loss: 1648.05460843)\n",
    "[2016-09-02 20:41:55,827] [INFO] Finished epoch 300. (Avg. training loss: 1574.80913405)\n",
    "[2016-09-02 20:42:21,778] [INFO] Finished epoch 310. (Avg. training loss: 1603.2134122)\n",
    "[2016-09-02 20:42:47,699] [INFO] Finished epoch 320. (Avg. training loss: 1554.92467221)\n",
    "[2016-09-02 20:43:13,587] [INFO] Finished epoch 330. (Avg. training loss: 1510.93893363)\n",
    "[2016-09-02 20:43:39,812] [INFO] Finished epoch 340. (Avg. training loss: 1467.54254913)\n",
    "[2016-09-02 20:44:05,688] [INFO] Finished epoch 350. (Avg. training loss: 1440.12515883)\n",
    "[2016-09-02 20:44:31,621] [INFO] Finished epoch 360. (Avg. training loss: 1422.47295414)\n",
    "[2016-09-02 20:44:57,927] [INFO] Finished epoch 370. (Avg. training loss: 1444.78291529)\n",
    "[2016-09-02 20:45:24,529] [INFO] Finished epoch 380. (Avg. training loss: 1392.09626389)\n",
    "[2016-09-02 20:45:50,543] [INFO] Finished epoch 390. (Avg. training loss: 1384.02797976)\n",
    "[2016-09-02 20:46:16,563] [INFO] Finished epoch 400. (Avg. training loss: 1345.65613417)\n",
    "[2016-09-02 20:46:42,446] [INFO] Finished epoch 410. (Avg. training loss: 1358.62544875)\n",
    "[2016-09-02 20:47:08,529] [INFO] Finished epoch 420. (Avg. training loss: 1372.39384114)\n",
    "[2016-09-02 20:47:34,725] [INFO] Finished epoch 430. (Avg. training loss: 1314.77864317)\n",
    "[2016-09-02 20:48:00,873] [INFO] Finished epoch 440. (Avg. training loss: 1336.18339539)\n",
    "[2016-09-02 20:48:27,202] [INFO] Finished epoch 450. (Avg. training loss: 1319.19177315)\n",
    "[2016-09-02 20:48:53,409] [INFO] Finished epoch 460. (Avg. training loss: 1311.66452096)\n",
    "[2016-09-02 20:49:19,906] [INFO] Finished epoch 470. (Avg. training loss: 1288.18096993)\n",
    "[2016-09-02 20:49:46,107] [INFO] Finished epoch 480. (Avg. training loss: 1300.70907697)\n",
    "[2016-09-02 20:50:12,178] [INFO] Finished epoch 490. (Avg. training loss: 1299.08323045)\n",
    "[2016-09-02 20:50:38,245] [INFO] Finished epoch 500. (Avg. training loss: 1262.9536653)\n",
    "[2016-09-02 20:51:04,312] [INFO] Finished epoch 510. (Avg. training loss: 1285.90589003)\n",
    "[2016-09-02 20:51:30,407] [INFO] Finished epoch 520. (Avg. training loss: 1294.46736214)\n",
    "[2016-09-02 20:51:56,662] [INFO] Finished epoch 530. (Avg. training loss: 1303.53440371)\n",
    "[2016-09-02 20:52:22,815] [INFO] Finished epoch 540. (Avg. training loss: 1249.16370045)\n",
    "[2016-09-02 20:52:48,962] [INFO] Finished epoch 550. (Avg. training loss: 1236.94174333)\n",
    "[2016-09-02 20:53:15,086] [INFO] Finished epoch 560. (Avg. training loss: 1224.01751952)\n",
    "[2016-09-02 20:53:41,849] [INFO] Finished epoch 570. (Avg. training loss: 1224.03992566)\n",
    "[2016-09-02 20:54:08,209] [INFO] Finished epoch 580. (Avg. training loss: 1230.53211316)\n",
    "[2016-09-02 20:54:34,086] [INFO] Finished epoch 590. (Avg. training loss: 1234.63750805)\n",
    "[2016-09-02 20:54:59,818] [INFO] Finished epoch 600. (Avg. training loss: 1221.07882378)\n",
    "[2016-09-02 20:55:26,642] [INFO] Finished epoch 610. (Avg. training loss: 1185.65967248)\n",
    "[2016-09-02 20:55:52,400] [INFO] Finished epoch 620. (Avg. training loss: 1194.03575446)\n",
    "[2016-09-02 20:56:18,263] [INFO] Finished epoch 630. (Avg. training loss: 1194.08644208)\n",
    "[2016-09-02 20:56:44,197] [INFO] Finished epoch 640. (Avg. training loss: 1183.59341639)\n",
    "[2016-09-02 20:57:10,383] [INFO] Finished epoch 650. (Avg. training loss: 1183.01943727)\n",
    "[2016-09-02 20:57:36,872] [INFO] Finished epoch 660. (Avg. training loss: 1158.40334736)\n",
    "[2016-09-02 20:58:02,976] [INFO] Finished epoch 670. (Avg. training loss: 1174.4918095)\n",
    "[2016-09-02 20:58:29,014] [INFO] Finished epoch 680. (Avg. training loss: 1199.12700064)\n",
    "[2016-09-02 20:58:54,746] [INFO] Finished epoch 690. (Avg. training loss: 1160.72963125)\n",
    "[2016-09-02 20:59:20,790] [INFO] Finished epoch 700. (Avg. training loss: 1165.32282188)\n",
    "[2016-09-02 20:59:46,938] [INFO] Finished epoch 710. (Avg. training loss: 1174.37212615)\n",
    "[2016-09-02 21:00:13,340] [INFO] Finished epoch 720. (Avg. training loss: 1169.23551282)\n",
    "[2016-09-02 21:00:39,339] [INFO] Finished epoch 730. (Avg. training loss: 1122.53124688)\n",
    "[2016-09-02 21:01:05,179] [INFO] Finished epoch 740. (Avg. training loss: 1157.93275036)\n",
    "[2016-09-02 21:01:31,381] [INFO] Finished epoch 750. (Avg. training loss: 1158.09665056)\n",
    "[2016-09-02 21:01:57,537] [INFO] Finished epoch 760. (Avg. training loss: 1139.63393333)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR = 0.0001\n",
      "[2016-09-08 19:16:31,476] [INFO] Starting training phase.\n",
      "[2016-09-08 19:16:59,652] [INFO] Finished epoch 0. (Avg. training loss: 3728.85334084)\n",
      "[2016-09-08 19:17:41,616] [INFO] Finished epoch 10. (Avg. training loss: 446.906148911)\n",
      "[2016-09-08 19:18:02,596] [INFO] Finished epoch 20. (Avg. training loss: 230.02659)\n",
      "[2016-09-08 19:18:23,327] [INFO] Finished epoch 30. (Avg. training loss: 152.64104505)\n",
      "[2016-09-08 19:18:44,082] [INFO] Finished epoch 40. (Avg. training loss: 114.153651671)\n",
      "[2016-09-08 19:19:04,807] [INFO] Finished epoch 50. (Avg. training loss: 93.8099693385)\n",
      "[2016-09-08 19:19:25,501] [INFO] Finished epoch 60. (Avg. training loss: 82.3407104232)\n",
      "[2016-09-08 19:19:46,054] [INFO] Finished epoch 70. (Avg. training loss: 75.7892449119)\n",
      "[2016-09-08 19:20:06,673] [INFO] Finished epoch 80. (Avg. training loss: 71.4349764911)\n",
      "[2016-09-08 19:20:27,154] [INFO] Finished epoch 90. (Avg. training loss: 68.7852852561)\n",
      "[2016-09-08 19:20:47,797] [INFO] Finished epoch 100. (Avg. training loss: 66.8919837258)\n",
      "[2016-09-08 19:21:08,646] [INFO] Finished epoch 110. (Avg. training loss: 65.8888210167)\n",
      "[2016-09-08 19:21:29,276] [INFO] Finished epoch 120. (Avg. training loss: 65.0218931328)\n",
      "[2016-09-08 19:21:50,186] [INFO] Finished epoch 130. (Avg. training loss: 64.5153313117)\n",
      "[2016-09-08 19:22:10,671] [INFO] Finished epoch 140. (Avg. training loss: 64.2945017598)\n",
      "[2016-09-08 19:22:31,350] [INFO] Finished epoch 150. (Avg. training loss: 63.9612216299)\n",
      "[2016-09-08 19:22:52,175] [INFO] Finished epoch 160. (Avg. training loss: 63.7822946852)\n",
      "[2016-09-08 19:23:12,963] [INFO] Finished epoch 170. (Avg. training loss: 63.3953738213)\n",
      "[2016-09-08 19:23:33,933] [INFO] Finished epoch 180. (Avg. training loss: 63.5159262094)\n",
      "[2016-09-08 19:23:54,722] [INFO] Finished epoch 190. (Avg. training loss: 63.3911959908)\n",
      "[2016-09-08 19:24:18,345] [INFO] Starting evaluation phase.\n",
      "/opt/conda/envs/python2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/envs/python2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[2016-09-08 19:24:18,893] [INFO] Evaluation (precision, recall, f1): [0.41174798449382544, 0.25697356424325835, 0.28087022940598949]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"\"\"LR = 0.0001\n",
    "[2016-09-08 19:16:31,476] [INFO] Starting training phase.\n",
    "[2016-09-08 19:16:59,652] [INFO] Finished epoch 0. (Avg. training loss: 3728.85334084)\n",
    "[2016-09-08 19:17:41,616] [INFO] Finished epoch 10. (Avg. training loss: 446.906148911)\n",
    "[2016-09-08 19:18:02,596] [INFO] Finished epoch 20. (Avg. training loss: 230.02659)\n",
    "[2016-09-08 19:18:23,327] [INFO] Finished epoch 30. (Avg. training loss: 152.64104505)\n",
    "[2016-09-08 19:18:44,082] [INFO] Finished epoch 40. (Avg. training loss: 114.153651671)\n",
    "[2016-09-08 19:19:04,807] [INFO] Finished epoch 50. (Avg. training loss: 93.8099693385)\n",
    "[2016-09-08 19:19:25,501] [INFO] Finished epoch 60. (Avg. training loss: 82.3407104232)\n",
    "[2016-09-08 19:19:46,054] [INFO] Finished epoch 70. (Avg. training loss: 75.7892449119)\n",
    "[2016-09-08 19:20:06,673] [INFO] Finished epoch 80. (Avg. training loss: 71.4349764911)\n",
    "[2016-09-08 19:20:27,154] [INFO] Finished epoch 90. (Avg. training loss: 68.7852852561)\n",
    "[2016-09-08 19:20:47,797] [INFO] Finished epoch 100. (Avg. training loss: 66.8919837258)\n",
    "[2016-09-08 19:21:08,646] [INFO] Finished epoch 110. (Avg. training loss: 65.8888210167)\n",
    "[2016-09-08 19:21:29,276] [INFO] Finished epoch 120. (Avg. training loss: 65.0218931328)\n",
    "[2016-09-08 19:21:50,186] [INFO] Finished epoch 130. (Avg. training loss: 64.5153313117)\n",
    "[2016-09-08 19:22:10,671] [INFO] Finished epoch 140. (Avg. training loss: 64.2945017598)\n",
    "[2016-09-08 19:22:31,350] [INFO] Finished epoch 150. (Avg. training loss: 63.9612216299)\n",
    "[2016-09-08 19:22:52,175] [INFO] Finished epoch 160. (Avg. training loss: 63.7822946852)\n",
    "[2016-09-08 19:23:12,963] [INFO] Finished epoch 170. (Avg. training loss: 63.3953738213)\n",
    "[2016-09-08 19:23:33,933] [INFO] Finished epoch 180. (Avg. training loss: 63.5159262094)\n",
    "[2016-09-08 19:23:54,722] [INFO] Finished epoch 190. (Avg. training loss: 63.3911959908)\n",
    "[2016-09-08 19:24:18,345] [INFO] Starting evaluation phase.\n",
    "/opt/conda/envs/python2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
    "  'precision', 'predicted', average, warn_for)\n",
    "/opt/conda/envs/python2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
    "  'precision', 'predicted', average, warn_for)\n",
    "[2016-09-08 19:24:18,893] [INFO] Evaluation (precision, recall, f1): [0.41174798449382544, 0.25697356424325835, 0.28087022940598949]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
